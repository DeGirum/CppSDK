<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>DeGirum AI Client for C++ Reference Guide: DG::AIModelAsync Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="degirum64.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">DeGirum AI Client for C++ Reference Guide
   &#160;<span id="projectnumber">v1.0.1</span>
   </div>
   <div id="projectbrief">DeGirum AI Client for C++ Reference Guide</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceDG.html">DG</a></li><li class="navelem"><a class="el" href="classDG_1_1AIModelAsync.html">AIModelAsync</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classDG_1_1AIModelAsync-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">DG::AIModelAsync Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p><a class="el" href="classDG_1_1AIModelAsync.html" title="AIModelAsync is DeGirum AI client API class for efficient pipelined asynchronous inference.">AIModelAsync</a> is DeGirum AI client API class for efficient pipelined asynchronous inference.  
 <a href="classDG_1_1AIModelAsync.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="dg__model__api_8h_source.html">dg_model_api.h</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:adfa9cbec9241ac0e413ddc647444dad2"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classDG_1_1AIModelAsync.html#adfa9cbec9241ac0e413ddc647444dad2">callback_t</a> = std::function&lt; void(const <a class="el" href="namespaceDG.html#a6bac255dbb312a6956fbd5a2d0447d95">json</a> &amp;inference_result, const std::string &amp;frame_info) &gt;</td></tr>
<tr class="separator:adfa9cbec9241ac0e413ddc647444dad2"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:aa0e5105262dee19f53f5166ddc7c3acc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classDG_1_1AIModelAsync.html#aa0e5105262dee19f53f5166ddc7c3acc">AIModelAsync</a> (const std::string &amp;server, const std::string &amp;model_name, <a class="el" href="classDG_1_1AIModelAsync.html#adfa9cbec9241ac0e413ddc647444dad2">callback_t</a> callback, const <a class="el" href="classDG_1_1ModelParamsReadAccess.html">ModelParamsReadAccess</a> &amp;model_params=<a class="el" href="classDG_1_1ModelParamsReadAccess.html">ModelParamsReadAccess</a>({}), size_t frame_queue_depth=8, size_t connection_timeout_ms=10000, size_t inference_timeout_ms=180000)</td></tr>
<tr class="separator:aa0e5105262dee19f53f5166ddc7c3acc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a25c1ada23af9b591a45171e9a795092b"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classDG_1_1AIModelAsync.html#a25c1ada23af9b591a45171e9a795092b">lastError</a> () const</td></tr>
<tr class="separator:a25c1ada23af9b591a45171e9a795092b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4262c7337d952d2543f8265791c0d535"><td class="memItemLeft" align="right" valign="top"><a id="a4262c7337d952d2543f8265791c0d535"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classDG_1_1AIModelAsync.html#a4262c7337d952d2543f8265791c0d535">outstandingResultsCountGet</a> () const</td></tr>
<tr class="memdesc:a4262c7337d952d2543f8265791c0d535"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the number of outstanding inference results posted so far. <br /></td></tr>
<tr class="separator:a4262c7337d952d2543f8265791c0d535"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1b12692b190b36e7e0e366f0bb59fdef"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classDG_1_1AIModelAsync.html#a1b12692b190b36e7e0e366f0bb59fdef">predict</a> (std::vector&lt; std::vector&lt; char &gt; &gt; &amp;data, const std::string &amp;frame_info=&quot;&quot;)</td></tr>
<tr class="separator:a1b12692b190b36e7e0e366f0bb59fdef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac0e68fd0f402c2ed4eecc1f63cad3132"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classDG_1_1AIModelAsync.html#ac0e68fd0f402c2ed4eecc1f63cad3132">setCallback</a> (<a class="el" href="classDG_1_1AIModelAsync.html#adfa9cbec9241ac0e413ddc647444dad2">callback_t</a> callback)</td></tr>
<tr class="separator:ac0e68fd0f402c2ed4eecc1f63cad3132"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c08f21e655345c17617df8d6d71774b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classDG_1_1AIModelAsync.html#a9c08f21e655345c17617df8d6d71774b">waitCompletion</a> ()</td></tr>
<tr class="separator:a9c08f21e655345c17617df8d6d71774b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01e5f514945867edae2ce91a1687f683"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classDG_1_1AIModelAsync.html#a01e5f514945867edae2ce91a1687f683">~AIModelAsync</a> ()</td></tr>
<tr class="separator:a01e5f514945867edae2ce91a1687f683"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p><a class="el" href="classDG_1_1AIModelAsync.html" title="AIModelAsync is DeGirum AI client API class for efficient pipelined asynchronous inference.">AIModelAsync</a> is DeGirum AI client API class for efficient pipelined asynchronous inference. </p>
<p>This class is used to perform AI model inference on AI server in efficient pipelined asynchronous manner using the mechanism of callbacks. For simple (but less efficient) synchronous non-pipelined inference use <a class="el" href="classDG_1_1AIModel.html" title="AIModel is DeGirum AI client API class for simple non-pipelined sequential inference.">AIModel</a> class.</p>
<p>On construction this class performs connection to AI server, selection of AI model, setting model run-time parameters, and installation of the client callback function. The client callback function is used to pass the inference results from the AI server to the client code.</p>
<p>Once constructed, it can be used to perform asynchronous AI inference by invoking <a class="el" href="classDG_1_1AIModelAsync.html#a1b12692b190b36e7e0e366f0bb59fdef">predict()</a> method. The <a class="el" href="classDG_1_1AIModelAsync.html#a1b12692b190b36e7e0e366f0bb59fdef">predict()</a> methods accept the input frame data and initiate the inference on the AI server. Each of those methods is a non-blocking method, i.e. it returns execution immediately after posting the frame data to the AI server. This allows calling those methods in a loop without waiting for the inference results, achieving the maximum AI server utilization. Once the inference of a frame is complete, and the inference result is received from the AI server, the client callback is invoked to dispatch the inference result. Such result handling via callback mechanism is performed in a thread, separate from the main execution thread. It means that the client callback function is called in asynchronous manner, thus the name of the class. </p>
</div><h2 class="groupheader">Member Typedef Documentation</h2>
<a id="adfa9cbec9241ac0e413ddc647444dad2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adfa9cbec9241ac0e413ddc647444dad2">&#9670;&nbsp;</a></span>callback_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="classDG_1_1AIModelAsync.html#adfa9cbec9241ac0e413ddc647444dad2">DG::AIModelAsync::callback_t</a> =  std::function&lt; void( const <a class="el" href="namespaceDG.html#a6bac255dbb312a6956fbd5a2d0447d95">json</a> &amp;inference_result, const std::string &amp;frame_info ) &gt;</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>User callback type. The callback is called asynchronously from the main execution thread as soon as prediction result is ready. Consecutive prediction result in a form of Json array is passed as the inference_result argument. Corresponding frame info string (provided to <a class="el" href="classDG_1_1AIModelAsync.html#a1b12692b190b36e7e0e366f0bb59fdef">predict()</a> call) is passed as the frame_info argument. </p>

</div>
</div>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="aa0e5105262dee19f53f5166ddc7c3acc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa0e5105262dee19f53f5166ddc7c3acc">&#9670;&nbsp;</a></span>AIModelAsync()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">DG::AIModelAsync::AIModelAsync </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>server</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>model_name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classDG_1_1AIModelAsync.html#adfa9cbec9241ac0e413ddc647444dad2">callback_t</a>&#160;</td>
          <td class="paramname"><em>callback</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classDG_1_1ModelParamsReadAccess.html">ModelParamsReadAccess</a> &amp;&#160;</td>
          <td class="paramname"><em>model_params</em> = <code><a class="el" href="classDG_1_1ModelParamsReadAccess.html">ModelParamsReadAccess</a>({})</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>frame_queue_depth</em> = <code>8</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>connection_timeout_ms</em> = <code>10000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>inference_timeout_ms</em> = <code>180000</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">explicit</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Constructor. Performs connection to AI server, selection of AI model, installing client callback, and optionally setting model run-time parameters. In case of server connection errors throws std::exception. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">server</td><td>is a string specifying server domain name/IP address and port. Format: "domain_name:port" or "xxx.xxx.xxx.xxx:port". If port is omitted, the default port is 8778. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">model_name</td><td>specifies the AI model to be used for inference. To obtain valid model name, either <a class="el" href="namespaceDG.html#ae6fb2ad5460b7160220feb74635845a1">modelFind()</a> or <a class="el" href="namespaceDG.html#a482a6ce0ec392df3b6f26db70b9b941e">modelzooListGet()</a> functions should be used. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">callback</td><td>is user callback functional, which will be called asynchronously from the main execution thread as soon as prediction result is ready. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">model_params</td><td>is runtime parameter collection, which defines the model runtime behavior. This is optional parameter: if not specified, then default runtime parameters (as defined in the model zoo) are used. ModelParamsWriter class instance can be used to conveniently define runtime parameters. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">frame_queue_depth</td><td>is the depth of the internal frame queue. If <a class="el" href="classDG_1_1AIModelAsync.html#a1b12692b190b36e7e0e366f0bb59fdef">predict()</a> methods are invoked too often and the number of non-processed (aka "outstanding") frames exceeds this parameter, the consecutive call to any <a class="el" href="classDG_1_1AIModelAsync.html#a1b12692b190b36e7e0e366f0bb59fdef">predict()</a> method will be blocked until the number of outstanding frames in the queue becomes smaller than the queue depth thus allowing to post one more frame. This is optional parameter: by default it is set to 8 frames. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">connection_timeout_ms</td><td>is the AI server connection timeout in milliseconds. This is optional parameter: by default it is set to 10 sec. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">inference_timeout_ms</td><td>is the AI server inference timeout in milliseconds. This is optional parameter: by default it is set to 180 sec. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a01e5f514945867edae2ce91a1687f683"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a01e5f514945867edae2ce91a1687f683">&#9670;&nbsp;</a></span>~AIModelAsync()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">DG::AIModelAsync::~AIModelAsync </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Destructor. Waits until all outstanding results are received and then closes the connection to AI server. Note: in case of server runtime error, all frames posted after that error was detected, will not be processed. </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a25c1ada23af9b591a45171e9a795092b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a25c1ada23af9b591a45171e9a795092b">&#9670;&nbsp;</a></span>lastError()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::string DG::AIModelAsync::lastError </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>If ever during consecutive calls to <a class="el" href="classDG_1_1AIModelAsync.html#a1b12692b190b36e7e0e366f0bb59fdef">predict()</a> methods AI server reported a run-time error, then this method will return the error message string, otherwise it returns an empty string. Note: in case of server runtime error, all frames posted after that error was detected, will not be processed. </p>

</div>
</div>
<a id="a1b12692b190b36e7e0e366f0bb59fdef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1b12692b190b36e7e0e366f0bb59fdef">&#9670;&nbsp;</a></span>predict()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void DG::AIModelAsync::predict </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; std::vector&lt; char &gt; &gt; &amp;&#160;</td>
          <td class="paramname"><em>data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>frame_info</em> = <code>&quot;&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Start the inference on given byte data vector. The byte vector contains the frame data, which depends on selected frame format. It can be either JPEG or bitmap depending on the model parameters. In case of errors throws std::exception. This is non-blocking call meaning that it returns execution immediately after posting the frame data to the AI server. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">data</td><td>is a vector of input data for each model input where each data element is a vector of bytes. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">frame_info</td><td>is optional frame information string to be passed to the client callback along with the frame result. You can pass arbitrary information as frame info. This simplifies matching results to frames in the client callback. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ac0e68fd0f402c2ed4eecc1f63cad3132"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac0e68fd0f402c2ed4eecc1f63cad3132">&#9670;&nbsp;</a></span>setCallback()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void DG::AIModelAsync::setCallback </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classDG_1_1AIModelAsync.html#adfa9cbec9241ac0e413ddc647444dad2">callback_t</a>&#160;</td>
          <td class="paramname"><em>callback</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Set user callback </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">callback</td><td>is user callback functional, which will be called asynchronously from the main execution thread as soon as prediction result is ready. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a9c08f21e655345c17617df8d6d71774b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9c08f21e655345c17617df8d6d71774b">&#9670;&nbsp;</a></span>waitCompletion()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void DG::AIModelAsync::waitCompletion </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Wait for completion of all outstanding inferences. This is blocking call: it returns when all outstanding frames are processed by AI server and all results are dispatched via client callback. You can continue calling <a class="el" href="classDG_1_1AIModelAsync.html#a1b12692b190b36e7e0e366f0bb59fdef">predict()</a> after call to this method - frame processing will restart automatically. </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li><a class="el" href="dg__model__api_8h_source.html">dg_model_api.h</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
</html>
